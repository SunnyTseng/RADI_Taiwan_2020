rasterize(., r, field = data_values$abd) %>%
extract(x = ., y = observation_coors)
values <- values[!is.na(values)] %>%
quantile(quantile)
return(values)
}
map_pred <- models %>%
mutate(map_pred_nb = map(.x = m_nb, .f = ~ predict(.x, newdata = pred_surf, type = "link", se.fit = TRUE) %>%
as_tibble() %>%
transmute(abd = .x$family$linkinv(fit)) %>%
bind_cols(pred_surf) %>%
select(x, y, abd)))
threshold <- map_pred %>%
mutate(threshold = map2_dbl(.x = map_pred_nb, .y = train_data,
.f = ~ thre(data_values = .x, data_checklists = .y)))
cols <- c("#febd2a", "#fa9e3c", "#f1824d", "#e66d5d", "#d6546e",
"#c43e7f", "#ac2693", "#9310a1", "#7702a8", "#5702a5", "#360498",
"#0d0887")
from = threshold$threshold %>% min()
map_pred_plot <- threshold %>%
mutate(map_nb = map2(.x = map_pred_nb, .y = threshold, .f = ~ ggplot() +
geom_tile(data = .x, aes(x = x, y = y), fill = "#e6e6e6") +
geom_tile(data = .x %>% filter(abd > .y),
aes(x = x, y = y, fill = abd)) +
scale_fill_gradientn(trans = "log",
colours = cols,
breaks = c(0, 2, 50),
limits = c(from = from, to = 100)) +
#geom_sf(data = tw_county %>%
#          st_crop(xmin = 119, xmax = 123, ymin = 20, ymax = 26) %>%
#          st_transform(crs = 3826),
#          col = "white", fill = NA, size = 0.3) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_blank(),
axis.title = element_blank(), axis.text = element_blank(),
axis.ticks = element_blank()))) %>%
select(day_of_year, threshold, map_pred_nb, map_nb)
map_pred_plot
models_map_nb <- prediction_maps(models = nb,
family = "nb",
workers = 16,
duration_minutes = 60,
effort_distance_km = 1,
number_observers = 1,
hour = 7,
dir_pred_surf = here("data", "processed", "prediciton_surface.csv"),
dir_pred_tif = here("data", "processed", "prediction_surface.tif"),
quantile = 0.2)
prediction_maps <- function(models = models,
family = "nb",
workers = 8,
duration_minutes = 60,
effort_distance_km = 1,
number_observers = 1,
hour = 6,
dir_pred_surf = here("data", "main_processed", "prediciton_surface.csv"),
dir_pred_tif = here("data", "main_processed", "prediction_surface.tif"),
quantile = 0.1){
plan(multisession, workers = workers)
# prediction surface
pred_surf <- read_csv(dir_pred_surf)
pred_surf <- pred_surf %>%
drop_na() %>%
mutate(duration_minutes = duration_minutes,
effort_distance_km = effort_distance_km,
number_observers = number_observers,
hour = hour)
r <- raster(dir_pred_tif)
# function for extracting threshold
thre <- function(data_values, data_checklists){
# coordinates for setting threshold
observation_coors <- data_checklists %>%
filter(observation_count >= 1) %>%
select(longitude, latitude) %>%
SpatialPoints(proj4string = CRS("+init=epsg:4326"))
values <- data_values %>%
select(x, y) %>%
SpatialPoints(proj4string = CRS("+init=epsg:3826")) %>%
rasterize(., r, field = data_values$abd) %>%
extract(x = ., y = observation_coors)
values <- values[!is.na(values)] %>%
quantile(quantile)
return(values)
}
# main code here
if (family == "nb"){
map_pred <- models %>%
mutate(map_pred_nb = map(.x = m_nb, .f = ~ predict(.x, newdata = pred_surf, type = "link", se.fit = TRUE) %>%
as_tibble() %>%
transmute(abd = .x$family$linkinv(fit)) %>%
bind_cols(pred_surf) %>%
select(x, y, abd)))
threshold <- map_pred %>%
mutate(threshold = map2_dbl(.x = map_pred_nb, .y = train_data,
.f = ~ thre(data_values = .x, data_checklists = .y)))
cols <- c("#febd2a", "#fa9e3c", "#f1824d", "#e66d5d", "#d6546e",
"#c43e7f", "#ac2693", "#9310a1", "#7702a8", "#5702a5", "#360498",
"#0d0887")
from = threshold$threshold %>% min()
map_pred_plot <- threshold %>%
mutate(map_nb = map2(.x = map_pred_nb, .y = threshold, .f = ~ ggplot() +
geom_tile(data = .x, aes(x = x, y = y), fill = "#e6e6e6") +
geom_tile(data = .x %>% filter(abd > .y),
aes(x = x, y = y, fill = abd)) +
scale_fill_gradientn(trans = "log",
colours = cols,
breaks = c(0, 2, 50),
limits = c(from = from, to = 100)) +
#geom_sf(data = tw_county %>%
#          st_crop(xmin = 119, xmax = 123, ymin = 20, ymax = 26) %>%
#          st_transform(crs = 3826),
#          col = "white", fill = NA, size = 0.3) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_blank(),
axis.title = element_blank(), axis.text = element_blank(),
axis.ticks = element_blank()))) %>%
select(day_of_year, threshold, map_pred_nb, map_nb)
} else {
inv_link <- binomial(link = "cloglog")$linkinv
map_pred <- models %>%
mutate(map_pred_ziplss = map(.x = m_ziplss, .f = ~ predict(.x, newdata = pred_surf, type = "link") %>%
as.data.frame() %>%
transmute(abd = inv_link(V2) * exp(V1)) %>%
bind_cols(pred_surf) %>%
select(x, y, abd)))
threshold <- map_pred %>%
mutate(threshold = map2_dbl(.x = map_pred_ziplss, .y = train_data,
.f = ~ thre(data_values = .x, data_checklists = .y)))
cols <- c("#febd2a", "#fa9e3c", "#f1824d", "#e66d5d", "#d6546e",
"#c43e7f", "#ac2693", "#9310a1", "#7702a8", "#5702a5", "#360498",
"#0d0887")
from = threshold$threshold %>% min()
map_pred_plot <- threshold %>%
mutate(map_ziplss = map2(.x = map_pred_ziplss, .y = threshold, .f = ~ ggplot() +
geom_tile(data = .x, aes(x = x, y = y), fill = "#e6e6e6") +
geom_tile(data = .x %>% filter(abd > .y),
aes(x = x, y = y, fill = abd)) +
scale_fill_gradientn(trans = "log",
colours = cols,
breaks = c(0, 2, 50),
limits = c(from = from, to = 100)) +
#geom_sf(data = tw_county %>%
#          st_crop(xmin = 119, xmax = 123, ymin = 20, ymax = 26) %>%
#          st_transform(crs = 3826),
#          col = "white", fill = NA, size = 0.3) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_blank(),
axis.title = element_blank(), axis.text = element_blank(),
axis.ticks = element_blank()))) %>%
select(day_of_year, threshold, map_pred_ziplss, map_ziplss)
}
return(map_pred_plot)
}
models_map_nb <- prediction_maps(models = nb,
family = "nb",
workers = 16,
duration_minutes = 60,
effort_distance_km = 1,
number_observers = 1,
hour = 7,
dir_pred_surf = here("data", "processed", "prediciton_surface.csv"),
dir_pred_tif = here("data", "processed", "prediction_surface.tif"),
quantile = 0.2)
models_map_nb
### Abundance maps
for(i in 1:53){
png(here("data", "processed", target_species,
paste0("test", target_species, "_week_", i, ".png")),
res = 300, width = 3, height = 4, units = 'in')
print(models_map_nb$map_nb[[i]])
dev.off()
}
### Abundance maps
for(i in 1:53){
png(here("data", "processed", target_species,
paste0(target_species, "_week_", i, ".png")),
res = 300, width = 3, height = 4, units = 'in')
print(models_map_nb$map_nb[[i]])
dev.off()
}
###############
### Library ###
###############
# data management
library(tidyverse)
library(data.table)
library(here)
library(lubridate)
library(janitor)
library(furrr)
library(ranger)
library(Boruta)
# GIS related
library(dggridR)
library(scam)
library(PresenceAbsence)
library(verification)
library(fields)
library(gridExtra)
library(raster)
library(rgdal)
library(sf)
library(twmap)
# plot related
library(RColorBrewer)
library(lattice)
library(ggcorrplot)
library(plotly)
#################
### Functions ###
#################
# resolve namespace conflicts
select <- dplyr::select
map <- purrr::map
projection <- raster::projection
# functions for different steps
source(here("R", "data_preparation_ebird.R"))
source(here("R", "data_preparation_predictors.R"))
source(here("R", "data_preparation_prediction_surface.R"))
source(here("R", "data_preparation_target_species.R"))
source(here("R", "modelling_random_forest.R"))
source(here("R", "modelling_stixel_grouping.R"))
source(here("R", "modelling_GAM.R"))
source(here("R", "modelling_evaluation.R"))
source(here("R", "prediction_maps.R"))
########################
### Data Preparation ###
########################
### cleaned data for eBird and predictors, umcommend when needed
data_preparation_ebird(EBD = here("data", "raw", "Taiwan_ebd", "ebd_TW_relMar-2020", "ebd_TW_relMar-2020.txt"),
path = here("data", "processed", "data_eBird_qualified.csv"),
start_year = 2015,
effort_max_distance = 5,
effort_max_duration = 300,
effort_max_observers = 10)
########################
### Data Preparation ###
########################
### cleaned data for eBird and predictors, umcommend when needed
data_preparation_ebird(EBD = here("data", "raw", "Taiwan_ebd", "ebd_TW_relMar-2020", "ebd_TW_relMar-2020.txt"),
path = here("data", "processed", "data_eBird_qualified.csv"),
start_year = 2015,
effort_max_distance = 5,
effort_max_duration = 300,
effort_max_observers = 10)
library(data.table)
install.packages(data.table)
install.packages("data.table")
library(data.table)
###############
### Library ###
###############
# data management
library(tidyverse)
library(data.table)
library(here)
library(lubridate)
library(janitor)
library(furrr)
library(ranger)
library(Boruta)
install.packages("janitor")
install.packages("furrr")
install.packages("ranger")
installed.packages("Boruta")
library(data.table)
library(here)
library(lubridate)
library(janitor)
library(furrr)
library(ranger)
library(Boruta)
install.packages("Boruta")
library(Boruta)
# GIS related
library(dggridR)
library(scam)
library(PresenceAbsence)
library(verification)
library(fields)
library(gridExtra)
library(raster)
library(rgdal)
library(sf)
library(twmap)
install.packages("dggridR")
install.packages("scam")
install.packages("PresenceAbsence")
install.pges("verificaiton")
install.packages("verificaiton")
install.packages("fields")
install.packages("gridExtra")
install.packages("raster")
install.packages("rgdal")
install.packages("sf")
install.packages("sf")
install.packages(("twmap"))
install.packages("RColorBrewer")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("ggcorrplot")
install.packages(plotly)
install.packages("plotly")
# data management
library(tidyverse)
library(data.table)
library(here)
library(lubridate)
library(janitor)
library(furrr)
library(ranger)
library(Boruta)
# GIS related
library(dggridR)
library(scam)
library(PresenceAbsence)
library(verification)
library(fields)
library(gridExtra)
library(raster)
library(rgdal)
library(sf)
library(twmap)
# plot related
library(RColorBrewer)
library(lattice)
library(ggcorrplot)
library(plotly)
remotes::install_github("shihjyun/twmap")
install.packages("remote")
library(tidyverse)
library(data.table)
library(here)
library(lubridate)
library(janitor)
library(furrr)
library(ranger)
library(Boruta)
# GIS related
library(dggridR)
library(scam)
library(PresenceAbsence)
library(verification)
library(fields)
library(gridExtra)
library(raster)
library(rgdal)
library(sf)
library(twmap) # remotes::install_github("shihjyun/twmap")
# plot related
library(RColorBrewer)
library(lattice)
library(ggcorrplot)
library(plotly)
install.packages("dggridR")
install.packages
install.packages("dggridR")
install_github('r-barnes/dggridR', vignette=TRUE)
library(devtools)
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
library(devtools)
install_github('r-barnes/dggridR', vignette=TRUE)
library(devtools)
install_github('r-barnes/dggridR', vignette=TRUE)
library(tidyverse)
library(data.table)
library(here)
library(lubridate)
library(janitor)
library(furrr)
library(ranger)
library(Boruta)
# GIS related
library(dggridR)
install_github('r-barnes/dggridR', vignette=TRUE)
library(devtools)
install_github('r-barnes/dggridR', vignette=TRUE)
# GIS related
library(dggridR) ## devtools::install_github('r-barnes/dggridR', vignette=TRUE)
install.packages(dggridR)
devtools::install_github('r-barnes/dggridR', vignette=TRUE)
library(dggridR)
devtools::install_github('r-barnes/dggridR', vignette=TRUE)
# GIS related
library(dggridR) ## devtools::install_github('r-barnes/dggridR', vignette=TRUE)
library(scam)
library(PresenceAbsence)
library(verification)
install.packages(verification)
install.packages("verification")
library(verification)
library(fields)
library(gridExtra)
library(raster)
library(rgdal)
library(sf)
library(twmap) ## remotes::install_github("shihjyun/twmap")
remotes::install_github("shihjyun/twmap")
library(twmap) ## remotes::install_github("shihjyun/twmap")
# plot related
library(RColorBrewer)
library(lattice)
library(ggcorrplot)
library(plotly)
#################
### Functions ###
#################
# resolve namespace conflicts
select <- dplyr::select
map <- purrr::map
projection <- raster::projection
# functions for different steps
source(here("R", "data_preparation_ebird.R"))
source(here("R", "data_preparation_predictors.R"))
source(here("R", "data_preparation_prediction_surface.R"))
source(here("R", "data_preparation_target_species.R"))
source(here("R", "modelling_random_forest.R"))
source(here("R", "modelling_stixel_grouping.R"))
source(here("R", "modelling_GAM.R"))
source(here("R", "modelling_evaluation.R"))
source(here("R", "prediction_maps.R"))
########################
### Data Preparation ###
########################
### cleaned data for eBird and predictors, umcommend when needed
data_preparation_ebird(EBD = here("data", "raw", "Taiwan_ebd", "ebd_TW_relMar-2020", "ebd_TW_relMar-2020.txt"),
path = here("data", "processed", "data_eBird_qualified.csv"),
start_year = 2015,
effort_max_distance = 5,
effort_max_duration = 300,
effort_max_observers = 10)
########################
### Data Preparation ###
########################
### cleaned data for eBird and predictors, umcommend when needed
data_preparation_ebird(EBD = here("data", "raw", "Taiwan_ebd", "ebd_TW_relMar-2020", "ebd_TW_relMar-2020.txt"),
path = here("data", "processed", "data_eBird_qualified.csv"),
start_year = 2015,
effort_max_distance = 5,
effort_max_duration = 300,
effort_max_observers = 10)
########################
### Data Preparation ###
########################
### cleaned data for eBird and predictors, umcommend when needed
data_preparation_ebird(EBD = here("data", "raw", "Taiwan_ebd", "ebd_TW_relMar-2020", "ebd_TW_relMar-2020.txt"),
path = here("data", "processed", "data_eBird_qualified.csv"),
start_year = 2015,
effort_max_distance = 5,
effort_max_duration = 300,
effort_max_observers = 10)
here()
########################
### Data Preparation ###
########################
### cleaned data for eBird and predictors, umcommend when needed
data_preparation_ebird(EBD = here("data", "raw", "Taiwan_ebd", "ebd_TW_relMar-2020", "ebd_TW_relMar-2020.txt"),
path = here("data", "processed", "data_eBird_qualified.csv"),
start_year = 2015,
effort_max_distance = 5,
effort_max_duration = 300,
effort_max_observers = 10)
########################
### Data Preparation ###
########################
### cleaned data for eBird and predictors, umcommend when needed
data_preparation_ebird(EBD = here("data", "raw", "Taiwan_ebd", "ebd_TW_relMar-2020", "ebd_TW_relMar-2020.txt"),
path = here("data", "processed", "data_eBird_qualified.csv"),
start_year = 2015,
effort_max_distance = 5,
effort_max_duration = 300,
effort_max_observers = 10)
########################
### Data Preparation ###
########################
### cleaned data for eBird and predictors, umcommend when needed
data_preparation_ebird(EBD = here("data", "raw", "Taiwan_ebd", "ebd_TW_relMar-2020", "ebd_TW_relMar-2020.txt"),
path = here("data", "processed", "data_eBird_qualified.csv"),
start_year = 2015,
effort_max_distance = 5,
effort_max_duration = 300,
effort_max_observers = 10)
data_preparation_ebird()
### cleaned predictors data according to the eBird checklists, umcommend when needed
data_preparation_predictors(dir_tiff = here("data", "raw", "Taiwan_environmental_dataset-master", "GeoTIFF_unzip"),
dir_eBird = here("data", "processed", "data_eBird_qualified.csv"),
path = here("data", "processed", "data_eBird_qualified_predictors.csv"))
### cleaned predictors data according to the eBird checklists, umcommend when needed
data_preparation_predictors(dir_tiff = here("data", "raw", "Taiwan_environmental_dataset-master", "GeoTIFF_unzip"),
dir_eBird = here("data", "processed", "data_eBird_qualified.csv"),
path = here("data", "processed", "data_eBird_qualified_predictors.csv"))
### cleaned predictors data according to the eBird checklists, umcommend when needed
data_preparation_predictors(dir_tiff = here("data", "raw", "Taiwan_environmental_dataset-master", "GeoTIFF_unzip"),
dir_eBird = here("data", "processed", "data_eBird_qualified.csv"),
path = here("data", "processed", "data_eBird_qualified_predictors.csv"))
